{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: openai in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (1.54.3)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: torch in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# 必要なライブラリをインストール\n",
    "! pip install pandas\n",
    "! pip install openai faiss-cpu transformers\n",
    "! pip install faiss-cpu\n",
    "! pip install torch\n",
    "! pip install numpy\n",
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU langchain langchain-community langchain_text_splitters langchain_chroma\n",
    "! pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part1. Load from the cloud on the Kaggle database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle is the famous platform which is offering machine learning compititions and opensource datasets\n",
    "\n",
    "Note that if you want to use Kaggle, you must have an account but one can easily log in using one's Google or Fakebook or Yahoo account\n",
    "\n",
    "We need to install Kaggle API (Application Programming Interface) first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Collecting certifi>=2023.7.22 (from kaggle)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from kaggle) (2.9.0)\n",
      "Collecting requests (from kaggle)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting urllib3 (from kaggle)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting webencodings (from bleach->kaggle)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->kaggle)\n",
      "  Downloading charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->kaggle)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105797 sha256=806d80a5e7a85bff173dd323dd57722f7b423ad2895e93f82d03411925a4c855\n",
      "  Stored in directory: c:\\users\\wangs\\appdata\\local\\pip\\cache\\wheels\\2b\\af\\a9\\70bffa2773af622d2ebea9c8d407720b86e67bd40c465bf837\n",
      "Successfully built kaggle\n",
      "Installing collected packages: webencodings, text-unidecode, urllib3, tqdm, python-slugify, idna, charset-normalizer, certifi, bleach, requests, kaggle\n",
      "Successfully installed bleach-6.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 idna-3.10 kaggle-1.6.17 python-slugify-8.0.4 requests-2.32.3 text-unidecode-1.3 tqdm-4.67.0 urllib3-2.2.3 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the Kaggle home page in your browser, click on the icon in the upper right corner and select \"Account\" from the menu bar to go to the account management page. In the \"API\" section, select \"Create New API Token\" to download the kaggle.json file to your computer. **After uploading that json file to colab by clicking on the folder symbol in the leftmost tab**, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "指定したディレクトリにAPIファイルを入れてください:C:/Users/wangs/.kaggle\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/wangs/.kaggle\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "print(f\"指定したディレクトリにAPIファイルを入れてください:{path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Page Token = CfDJ8GrUjsAKvhxNhvm67MmtKLl39PI19c56I5tY-a_zC4a4Hv2AGugR0W3XR5n4ElQhQ8XVOEzjSsXWZpCTF1zKo5Q\n",
      "    id  ref                                                       title                                          subtitle                                                                                                                                                                                                              author              \n",
      "------  --------------------------------------------------------  ---------------------------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------  \n",
      "121027  metaresearch/llama-3.2                                    Llama 3.2                                      The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out).                               Meta                \n",
      "145528  cohereforai/aya-expanse                                   Aya Expanse                                    Aya Expanse advances the state-of-the-art in multilingual capabilities to help bridge language gaps with AI.                                                                                                          CohereForAI         \n",
      "127417  abdullahmeda/qwen2.5                                      Qwen2.5                                                                                                                                                                                                                                                              Abdullah Meda       \n",
      "146350  dasbro/xgb_model                                          XGB_model                                                                                                                                                                                                                                                            dasbro              \n",
      "121954  google/gemma-2-2b-jpn-it                                  Gemma 2 2b JPN IT                              Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.                                                             Google              \n",
      "141350  ultralytics/yolo11                                        Ultralytics YOLO11                             Ultralytics YOLO 🚀 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.                                                                                 Ultralytics         \n",
      "  3301  google/gemma                                              Gemma                                          Gemma is a family of lightweight, open models built from the research and technology that Google used to create the Gemini models.                                                                                    Google              \n",
      "123481  takanashihumbert/qwen2.5                                  Qwen2.5                                                                                                                                                                                                                                                              Joseph              \n",
      "121030  metaresearch/llama-3.2-vision                             Llama 3.2 Vision                               The Llama 3.2-Vision collection of multimodal large language models (LLMs) is a collection of pretrained and instruction-tuned image reasoning generative models in 11B and 90B sizes (text + images in / text out).  Meta                \n",
      "  3533  keras/gemma                                               Gemma                                          Keras implementation of the Gemma model. This Keras 3 implementation will run on JAX, TensorFlow and PyTorch.                                                                                                         Keras               \n",
      "  1902  mistral-ai/mistral                                        Mistral                                        Mistral AI team is proud to release Mistral, the most powerful language model for its size to date.                                                                                                                   Mistral AI          \n",
      "141013  ultralytics/yolov8                                        Ultralytics YOLOv8                             Ultralytics YOLO 🚀 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.                                                                                 Ultralytics         \n",
      "141044  huikang/qwen2.5                                           qwen2.5                                                                                                                                                                                                                                                              Tong Hui Kang       \n",
      " 91102  metaresearch/llama-3.1                                    Llama 3.1                                      The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models in 8B, 70B and 405B sizes (text in/text out).                        Meta                \n",
      " 78150  keras/gemma2                                              Gemma 2                                        Keras implementation of the Gemma 2 model. This Keras 3 implementation will run on JAX, TensorFlow and PyTorch.                                                                                                       Keras               \n",
      "128845  jonathanchan/baai                                         BAAI                                                                                                                                                                                                                                                                 Jonathan Chan       \n",
      "152800  ai-singapore/gemma2-9b-cpt-sea-lionv3-instruct            gemma2-9b-cpt-sea-lionv3-instruct              Gemma2 9B CPT SEA-LIONv3 Instruct                                                                                                                                                                                     AI Singapore        \n",
      " 76277  google/gemma-2                                            Gemma 2                                        Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.                                                             Google              \n",
      "142464  mehulbhattacharya/healthy-bleached-coral-reef-classifier  Coral Reef Health Image Classifier using YOLO  Detect Bleached or Healthy Coral Reef                                                                                                                                                                                 Mehul Bhattacharya  \n",
      "147213  darraghdog/qwen-qwen2.5-math-7b-instruct                  Qwen-Qwen2.5-Math-7B-Instruct                                                                                                                                                                                                                                        Darragh             \n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.model_list_cli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                                                deadline             category                reward  teamCount  userHasEntered  \n",
      "---------------------------------------------------------------------------------  -------------------  ---------------  -------------  ---------  --------------  \n",
      "https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-2      2025-04-01 23:59:00  Featured         2,117,152 Usd        412           False  \n",
      "https://www.kaggle.com/competitions/gemma-language-tuning                          2025-01-15 00:59:00  Analytics          150,000 Usd          0           False  \n",
      "https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting  2025-01-13 23:59:00  Featured           120,000 Usd       1327           False  \n",
      "https://www.kaggle.com/competitions/gemini-long-context                            2024-12-01 23:59:00  Analytics          100,000 Usd          0           False  \n",
      "https://www.kaggle.com/competitions/nfl-big-data-bowl-2025                         2025-01-08 23:59:00  Analytics          100,000 Usd          0           False  \n",
      "https://www.kaggle.com/competitions/czii-cryo-et-object-identification             2025-02-05 23:59:00  Featured            75,000 Usd         52           False  \n",
      "https://www.kaggle.com/competitions/child-mind-institute-problematic-internet-use  2024-12-19 23:59:00  Featured            60,000 Usd       2183           False  \n",
      "https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics      2024-12-12 23:59:00  Featured            55,000 Usd       1101           False  \n",
      "https://www.kaggle.com/competitions/um-game-playing-strength-of-mcts-variants      2024-12-02 23:59:00  Research            50,000 Usd       1319           False  \n",
      "https://www.kaggle.com/competitions/playground-series-s4e11                        2024-11-30 23:59:00  Playground                Swag       1054           False  \n",
      "https://www.kaggle.com/competitions/titanic                                        2030-01-01 00:00:00  Getting Started      Knowledge      16172           False  \n",
      "https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started      Knowledge       5590           False  \n",
      "https://www.kaggle.com/competitions/spaceship-titanic                              2030-01-01 00:00:00  Getting Started      Knowledge       1700           False  \n",
      "https://www.kaggle.com/competitions/digit-recognizer                               2030-01-01 00:00:00  Getting Started      Knowledge       1568           False  \n",
      "https://www.kaggle.com/competitions/nlp-getting-started                            2030-01-01 00:00:00  Getting Started      Knowledge       1012           False  \n",
      "https://www.kaggle.com/competitions/store-sales-time-series-forecasting            2030-06-30 23:59:00  Getting Started      Knowledge        776           False  \n",
      "https://www.kaggle.com/competitions/connectx                                       2030-01-01 00:00:00  Getting Started      Knowledge        203           False  \n",
      "https://www.kaggle.com/competitions/gan-getting-started                            2030-07-01 23:59:00  Getting Started      Knowledge         87           False  \n",
      "https://www.kaggle.com/competitions/contradictory-my-dear-watson                   2030-07-01 23:59:00  Getting Started      Knowledge         44           False  \n",
      "https://www.kaggle.com/competitions/tpu-getting-started                            2030-06-03 23:59:00  Getting Started      Knowledge         43           False  \n"
     ]
    }
   ],
   "source": [
    "! kaggle competitions list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can download datasets by using following command\n",
    "~~~\n",
    "! kaggle datasets download <name-of-dataset>\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/noxmoon/chinese-official-daily-news-since-2016\n",
      "License(s): unknown\n",
      "Downloading chinese-official-daily-news-since-2016.zip to c:\\Users\\wangs\\Dropbox\\個人用\\授業\\博士課程\\人文_2024_3Q\\DH\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/8.43M [00:00<?, ?B/s]\n",
      " 12%|█▏        | 1.00M/8.43M [00:00<00:05, 1.34MB/s]\n",
      " 24%|██▎       | 2.00M/8.43M [00:00<00:02, 2.42MB/s]\n",
      " 36%|███▌      | 3.00M/8.43M [00:01<00:01, 3.05MB/s]\n",
      " 47%|████▋     | 4.00M/8.43M [00:02<00:02, 1.68MB/s]\n",
      " 59%|█████▉    | 5.00M/8.43M [00:02<00:01, 1.93MB/s]\n",
      " 71%|███████   | 6.00M/8.43M [00:03<00:01, 2.09MB/s]\n",
      " 83%|████████▎ | 7.00M/8.43M [00:03<00:00, 2.19MB/s]\n",
      " 95%|█████████▍| 8.00M/8.43M [00:04<00:00, 2.18MB/s]\n",
      "100%|██████████| 8.43M/8.43M [00:04<00:00, 2.29MB/s]\n",
      "100%|██████████| 8.43M/8.43M [00:04<00:00, 2.13MB/s]\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download noxmoon/chinese-official-daily-news-since-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chinese-official-daily-news-since-2016.zipを./extracted_dataに解凍しました。\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# ZIPファイルのパスを指定\n",
    "zip_file_path = \"chinese-official-daily-news-since-2016.zip\"\n",
    "extract_path = \"./extracted_data\"  # 解凍先ディレクトリを指定\n",
    "\n",
    "# 解凍先のディレクトリが存在しない場合は作成\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# ZIPファイルを解凍\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(f\"{zip_file_path}を{extract_path}に解凍しました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part2 make a RAG using ChatGPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tag</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>详细全文</td>\n",
       "      <td>陆军领导机构火箭军战略支援部队成立大会在京举行 习近平向中国人民解放军陆军火箭军战略支援部队...</td>\n",
       "      <td>中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会2015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>详细全文</td>\n",
       "      <td>中央军委印发《关于深化国防和军队改革的意见》</td>\n",
       "      <td>经中央军委主席习近平批准，中央军委近日印发了《关于深化国防和军队改革的意见》。\\n《意见》强...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>详细全文</td>\n",
       "      <td>《习近平关于严明党的纪律和规矩论述摘编》出版发行</td>\n",
       "      <td>由中共中央纪律检查委员会、中共中央文献研究室编辑的《习近平关于严明党的纪律和规矩论述摘编》一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>详细全文</td>\n",
       "      <td>以实际行动向党中央看齐 向高标准努力</td>\n",
       "      <td>广大党员干部正在积极学习习近平总书记在中央政治局专题民主生活会上的重要讲话。大家纷纷表示要把...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>详细全文</td>\n",
       "      <td>【年终特稿】关键之年 改革挺进深水区</td>\n",
       "      <td>刚刚过去的2015年，是全面深化改革的关键之年。改革集中发力在制约经济社会发展的深层次矛盾，...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   tag                                           headline  \\\n",
       "0  2016-01-01  详细全文  陆军领导机构火箭军战略支援部队成立大会在京举行 习近平向中国人民解放军陆军火箭军战略支援部队...   \n",
       "1  2016-01-01  详细全文                             中央军委印发《关于深化国防和军队改革的意见》   \n",
       "2  2016-01-01  详细全文                           《习近平关于严明党的纪律和规矩论述摘编》出版发行   \n",
       "3  2016-01-01  详细全文                                 以实际行动向党中央看齐 向高标准努力   \n",
       "4  2016-01-01  详细全文                                 【年终特稿】关键之年 改革挺进深水区   \n",
       "\n",
       "                                             content  \n",
       "0  中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会2015...  \n",
       "1  经中央军委主席习近平批准，中央军委近日印发了《关于深化国防和军队改革的意见》。\\n《意见》强...  \n",
       "2  由中共中央纪律检查委员会、中共中央文献研究室编辑的《习近平关于严明党的纪律和规矩论述摘编》一...  \n",
       "3  广大党员干部正在积极学习习近平总书记在中央政治局专题民主生活会上的重要讲话。大家纷纷表示要把...  \n",
       "4  刚刚过去的2015年，是全面深化改革的关键之年。改革集中发力在制约经济社会发展的深层次矛盾，...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSVファイルの読み込み\n",
    "file_path = 'extracted_data/chinese_news.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 最初の数行を確認\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データには以下の列があります：\n",
    "\n",
    "- date: ニュースの日付\n",
    "- tag: ニュースのタグ\n",
    "- headline: ニュースの見出し\n",
    "- content: ニュースの内容（この列を主に使用）\n",
    "\n",
    "次に、content列を使用してドキュメントのベクトル化とインデックス化を行い、RAGモデルの検索エンジン部分を作成します。faissを使ってインデックス化し、transformersを使ってテキストをベクトル化します。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wangs\\anaconda3\\envs\\DH\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "サンプルインデックスが正常に作成されました。\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# モデルとトークナイザーの準備（Sentence Transformersを使用）\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ベクトル化の関数\n",
    "def embed_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings[0].numpy()\n",
    "\n",
    "# サンプルデータの取得\n",
    "sample_data = data['headline'].sample(5000, random_state=1)  # ランダムに10件を抽出\n",
    "\n",
    "# サンプルデータでベクトル化とインデックス化を試行\n",
    "try:\n",
    "    sample_embeddings = np.array([embed_text(text) for text in sample_data])\n",
    "    sample_index = faiss.IndexFlatL2(sample_embeddings.shape[1])\n",
    "    sample_index.add(sample_embeddings)\n",
    "    print(\"サンプルインデックスが正常に作成されました。\")\n",
    "except Exception as e:\n",
    "    print(\"エラーが発生しました:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query, k=3):\n",
    "    # 質問をベクトル化\n",
    "    query_vector = embed_text(query).reshape(1, -1)\n",
    "    distances, indices = sample_index.search(query_vector, k)  # kは取得するドキュメント数\n",
    "    return [sample_data.iloc[i] for i in indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"\"\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "def generate_answer(query, retrieved_docs):\n",
    "    context = \"\\n\".join(retrieved_docs)\n",
    "    prompt = f\"以下のニュース情報に基づいて質問に答えてください。\\n\\n{context}\\n\\n質問: {query}\\n答え:\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1500\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成された答え: 2016年1月1日のニュースによれば、北京市は「十三五」规划を発表し、2020年までに北京城六区の常住人口を2014年の基準から約15%減少させることを目指しています。この対策には非首都機能の調整と人口の最適化が含まれています。\n",
      "\n",
      "また、2015年末までに全国で783万套の保障性安居工程が開工し、772万套が基本的に完成しました。これは2015年度の目標を上回る達成です。特に棚戸区改造に関しては601万套が開工し、年度\n"
     ]
    }
   ],
   "source": [
    "# 質問を設定し、検索と生成を行う\n",
    "query = \"2016-01-01のニュースをまとめてください\"\n",
    "retrieved_docs = retrieve_documents(query)\n",
    "answer = generate_answer(query, retrieved_docs)\n",
    "\n",
    "print(\"生成された答え:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成された答え: 提供された情報には北京ダックに関するニュースは含まれていません。代わりに、以下のニュースが報告されています：\n",
      "\n",
      "1. 北京の鉄道警察が偽チケットの製造および販売拠点を捜索し、壊滅させました。\n",
      "2. 习近平（シー・チンピング）国家主席が北京市の八一学校を訪問し、教育方針の全面的な実施を強調し、中国の基礎教育を向上させる努力を呼びかけました。\n",
      "3. 北京市は非首都機能の解消を進めており、産業の増減が報告されています。\n",
      "\n",
      "北京ダックに関する情報が必要であれば、別のソースを参照する必要があります。\n"
     ]
    }
   ],
   "source": [
    "# 質問を設定し、検索と生成を行う\n",
    "query = \"北京ダックのニュースをまとめてください\"\n",
    "retrieved_docs = retrieve_documents(query)\n",
    "answer = generate_answer(query, retrieved_docs)\n",
    "\n",
    "print(\"生成された答え:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、情報検索を実行し、ユーザーの質問に関連するニュース記事を検索する仕組みを構築します。質問から類似の文書を検索して応答を生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDFベクトル化を再設定：次元数を削減\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # 次元を5000 -> 1000に削減\n",
    "tfidf_matrix = vectorizer.fit_transform(data)\n",
    "\n",
    "# k近傍法を使ったスパース行列でのインデックス作成\n",
    "knn_index = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn_index.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'headline': '陆军领导机构火箭军战略支援部队成立大会在京举行 习近平向中国人民解放军陆军火箭军战略支援部队授予军旗并致训词',\n",
       "  'content': '中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会2015年12月31日在八一大楼隆重举行。中共中央总书记、国家主席、中央军委主席习近平向陆军、火箭军、战略支援部队授予军旗并致训词，代表党中央和中央军委向同志们、向全军部队致以热烈祝贺，强调要坚持以党在新形势下的强军目标为引领，深入贯彻新形势下军事战略方针，全面实施改革强军战略，坚定不移走中国特色强军之路，时刻听从党和人民召唤，忠实履行党和人民赋予的神圣使命，为实现中国梦强军梦作出新的更大的贡献。\\n下午4时，成立大会开始，全场高唱国歌。仪仗礼兵护卫着鲜艳军旗，正步行进到主席台前。习近平将军旗郑重授予陆军司令员李作成、政治委员刘雷，火箭军司令员魏凤和政治委员王家胜，战略支援部队司令员高津、政治委员刘福连。陆军、火箭军、战略支援部队主要领导，军容严整、精神抖擞，向习近平敬礼，从习近平手中接过军旗。全场官兵向军旗敬礼。\\n授旗仪式后，习近平致训词。他指出：“成立陆军领导机构、火箭军、战略支援部队，是党中央和中央军委着眼实现中国梦强军梦作出的重大决策，是构建中国特色现代军事力量体系的战略举措，必将成为我军现代化建设的一个重要里程碑，载入人民军队史册。”\\n习近平强调，陆军是党最早建立和领导的武装力量，历史悠久，敢打善战，战功卓著，为党和人民建立了不朽功勋。陆军对维护国家主权、安全和发展利益具有不可替代的作用。陆军全体官兵要弘扬陆军光荣传统和优良作风，适应信息化时代陆军建设模式和运用方式的深刻变化，探索陆军发展特点和规律，按照机动作战、立体攻防的战略要求，加强顶层设计和领导管理，优化力量结构和部队编成，加快实现区域防卫型向全域作战型转变，努力建设一支强大的现代化新型陆军。\\n习近平强调，火箭军是我国战略威慑的核心力量，是我国大国地位的战略支撑，是维护国家安全的重要基石。火箭军全体官兵要把握火箭军的职能定位和使命任务，按照核常兼备、全域慑战的战略要求，增强可信可靠的核威慑和核反击能力，加强中远程精确打击力量建设，增强战略制衡能力，努力建设一支强大的现代化火箭军。\\n习近平强调，战略支援部队是维护国家安全的新型作战力量，是我军新质作战能力的重要增长点。战略支援部队全体官兵要坚持体系融合、军民融合，努力在关键领域实现跨越发展，高标准高起点推进新型作战力量加速发展、一体发展，努力建设一支强大的现代化战略支援部队。\\n习近平强调：“你们要坚持以党在新形势下的强军目标为引领，深入贯彻新形势下军事战略方针，全面实施改革强军战略，坚定不移走中国特色强军之路，时刻听从党和人民的召唤，忠诚履行党和人民赋予的神圣使命，为实现中国梦强军梦作出新的更大的贡献。”\\n刘雷、王家胜、刘福连分别代表陆军、火箭军、战略支援部队发言，一致表示，坚决贯彻习主席训词，任何时候任何情况下都坚决听从党中央、中央军委和习主席指挥，牢记职责使命，忠诚履职尽责，带领部队圆满完成各项任务。\\n成立大会上，中共中央政治局委员、中央军委副主席范长龙宣读了习近平主席签发的中央军委关于组建陆军领导机构、火箭军、战略支援部队及其领导班子成员任职命令和决定。中共中央政治局委员、中央军委副主席许其亮主持大会。\\n大会在嘹亮的军歌声中结束。之后，习近平亲切接见了陆军、火箭军、战略支援部队领导班子成员，并同大家合影留念。\\n中央军委委员常万全、房峰辉、张阳、赵克石、张又侠、吴胜利、马晓天出席大会。四总部、驻京各大单位和军委办公厅领导参加大会。\\n'},\n",
       " {'headline': '中央军委印发《关于深化国防和军队改革的意见》',\n",
       "  'content': '经中央军委主席习近平批准，中央军委近日印发了《关于深化国防和军队改革的意见》。\\n《意见》强调，党的十八大以来，党中央、中央军委和习主席围绕实现强军目标，统筹军队革命化、现代化、正规化建设，统筹军事力量建设和运用，统筹经济建设和国防建设，制定新形势下军事战略方针，提出一系列重大方针原则，作出一系列重大决策部署。贯彻落实党中央、中央军委和习主席的重大战略谋划和战略设计，必须深化国防和军队改革，全面实施改革强军战略，坚定不移走中国特色强军之路。\\n《意见》指出，深化国防和军队改革的指导思想是，深入贯彻党的十八大和十八届三中、四中、五中全会精神，以马克思列宁主义、毛泽东思想、邓小平理论、“三个代表”重要思想、科学发展观为指导，深入贯彻习主席系列重要讲话精神特别是国防和军队建设重要论述，按照“四个全面”战略布局要求，以党在新形势下的强军目标为引领，贯彻新形势下军事战略方针，全面实施改革强军战略，着力解决制约国防和军队发展的体制性障碍、结构性矛盾、政策性问题，推进军队组织形态现代化，进一步解放和发展战斗力，进一步解放和增强军队活力，建设同我国国际地位相称、同国家安全和发展利益相适应的巩固国防和强大军队，为实现“两个一百年”奋斗目标、实现中华民族伟大复兴的中国梦提供坚强力量保证。\\n《意见》强调，深化国防和军队改革要坚持以下基本原则：坚持正确政治方向，坚持向打仗聚焦，坚持创新驱动，坚持体系设计，坚持法治思维，坚持积极稳妥。\\n《意见》指出，深化国防和军队改革总体目标是，牢牢把握“军委管总、战区主战、军种主建”的原则，以领导管理体制、联合作战指挥体制改革为重点，协调推进规模结构、政策制度和军民融合深度发展改革。2020年前，在领导管理体制、联合作战指挥体制改革上取得突破性进展，在优化规模结构、完善政策制度、推动军民融合深度发展等方面改革上取得重要成果，努力构建能够打赢信息化战争、有效履行使命任务的中国特色现代军事力量体系，进一步完善中国特色社会主义军事制度。\\n《意见》明确了领导管理体制、联合作战指挥体制、军队规模结构、部队编成、新型军事人才培养、政策制度、军民融合发展、武装警察部队指挥管理体制和力量结构、军事法治体系等方面的主要任务。\\n《意见》强调，深化国防和军队改革是一场整体性、革命性变革，必须始终在党中央、中央军委和习主席的统一领导下，深入贯彻中央军委改革工作会议精神，坚持把加强教育、统一思想贯穿始终，把强化责任、落细落实贯穿始终，把依法推进、稳扎稳打贯穿始终，把底线思维、管控风险贯穿始终，以坚强有力的组织领导保证各项改革任务圆满完成。\\n'},\n",
       " {'headline': '《习近平关于严明党的纪律和规矩论述摘编》出版发行',\n",
       "  'content': '由中共中央纪律检查委员会、中共中央文献研究室编辑的《习近平关于严明党的纪律和规矩论述摘编》一书，近日由中央文献出版社、中国方正出版社出版，在全国发行。\\n党的十八大以来，中共中央总书记、国家主席、中央军委主席习近平高度重视全面从严治党，站在党和国家全局的高度，围绕严明党的纪律和规矩，发表了一系列重要论述，为加强党的建设，深入推进党风廉政建设和反腐败斗争提供了思想指导和行动指南。认真学习贯彻这些重要论述，对于全党深刻认识坚持党的领导、加强党的建设的极端重要性，准确把握纪律建设的基本要求，贯彻执行新修订的廉洁自律准则和党纪处分条例，坚定不移推进全面从严治党，具有十分重要的意义。\\n《论述摘编》共分7个专题：加强纪律建设是全面从严治党的治本之策；严明党的纪律，首要的就是严明政治纪律；严明党的组织纪律，增强组织纪律性；创新党内法规制度，把各项纪律和规矩立起来；使纪律真正成为带电的高压线;抓住领导干部这个“关键少数”；落实管党治党责任，强化监督执纪问责。书中收入200段论述，摘自习近平同志2012年11月16日至2015年10月29日期间的讲话、文章等40多篇重要文献。其中许多论述是第一次公开发表。\\n日前，中央纪委机关、中央宣传部联合下发通知，要求各级党组织认真组织学习习近平总书记关于严明党的纪律和规矩的重要论述，切实担负起全面从严治党的主体责任，坚持高标准，守住底线，真正把纪律立起来、严起来，执行到位，为协调推进“四个全面”战略布局提供坚强纪律保证。\\n从今天起，《中国共产党廉洁自律准则》和《中国共产党纪律处分条例》正式施行。\\n'},\n",
       " {'headline': '以实际行动向党中央看齐 向高标准努力',\n",
       "  'content': '广大党员干部正在积极学习习近平总书记在中央政治局专题民主生活会上的重要讲话。大家纷纷表示要把践行“三严三实”体现在解决问题的实践当中，以实际行动向党中央看齐、向高标准努力。\\n中央政治局专题民主生活会上提出，在践行‘三严三实’上要定位准、标杆高、行之笃，以实际行动不辜负人民重托。\\n践行“三严三实”，就要坚定理想信念，永葆全心为民的公仆情怀，保持对党忠诚的政治品格，做政治上的明白人。\\n'}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# インデックスに登録されたサンプル数を確認\n",
    "registered_samples = tfidf_matrix.shape[0]\n",
    "\n",
    "# 検索クエリを実行する際に、登録サンプル数以下のn_neighborsを設定\n",
    "def search_news_fixed(query, k=5):\n",
    "    # kを登録サンプル数以下に調整\n",
    "    k = min(k, registered_samples)\n",
    "    # 質問をTF-IDFでベクトル化\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    # 最近傍検索\n",
    "    distances, indices = knn_index.kneighbors(query_vector, n_neighbors=k)\n",
    "    # 検索結果を返す\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        results.append({\n",
    "            \"headline\": data.iloc[idx][\"headline\"],\n",
    "            \"content\": data.iloc[idx][\"content\"]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# 修正版で検索の例\n",
    "example_query = \"国防と軍隊の改革\"\n",
    "search_results_fixed = search_news_fixed(example_query)\n",
    "\n",
    "# 修正版の検索結果を表示\n",
    "search_results_fixed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
