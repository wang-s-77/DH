{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: openai in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (1.54.3)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: torch in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "! pip install pandas\n",
    "! pip install openai faiss-cpu transformers\n",
    "! pip install faiss-cpu\n",
    "! pip install torch\n",
    "! pip install numpy\n",
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU langchain langchain-community langchain_text_splitters langchain_chroma\n",
    "! pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part1. Load from the cloud on the Kaggle database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle is the famous platform which is offering machine learning compititions and opensource datasets\n",
    "\n",
    "Note that if you want to use Kaggle, you must have an account but one can easily log in using one's Google or Fakebook or Yahoo account\n",
    "\n",
    "We need to install Kaggle API (Application Programming Interface) first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Collecting certifi>=2023.7.22 (from kaggle)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from kaggle) (2.9.0)\n",
      "Collecting requests (from kaggle)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting urllib3 (from kaggle)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting webencodings (from bleach->kaggle)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->kaggle)\n",
      "  Downloading charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->kaggle)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\wangs\\anaconda3\\envs\\dh\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105797 sha256=806d80a5e7a85bff173dd323dd57722f7b423ad2895e93f82d03411925a4c855\n",
      "  Stored in directory: c:\\users\\wangs\\appdata\\local\\pip\\cache\\wheels\\2b\\af\\a9\\70bffa2773af622d2ebea9c8d407720b86e67bd40c465bf837\n",
      "Successfully built kaggle\n",
      "Installing collected packages: webencodings, text-unidecode, urllib3, tqdm, python-slugify, idna, charset-normalizer, certifi, bleach, requests, kaggle\n",
      "Successfully installed bleach-6.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 idna-3.10 kaggle-1.6.17 python-slugify-8.0.4 requests-2.32.3 text-unidecode-1.3 tqdm-4.67.0 urllib3-2.2.3 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the Kaggle home page in your browser, click on the icon in the upper right corner and select \"Account\" from the menu bar to go to the account management page. In the \"API\" section, select \"Create New API Token\" to download the kaggle.json file to your computer. **After uploading that json file to colab by clicking on the folder symbol in the leftmost tab**, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«APIãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¥ã‚Œã¦ãã ã•ã„:C:/Users/wangs/.kaggle\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/wangs/.kaggle\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "print(f\"æŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«APIãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¥ã‚Œã¦ãã ã•ã„:{path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Page Token = CfDJ8GrUjsAKvhxNhvm67MmtKLl39PI19c56I5tY-a_zC4a4Hv2AGugR0W3XR5n4ElQhQ8XVOEzjSsXWZpCTF1zKo5Q\n",
      "    id  ref                                                       title                                          subtitle                                                                                                                                                                                                              author              \n",
      "------  --------------------------------------------------------  ---------------------------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------  \n",
      "121027  metaresearch/llama-3.2                                    Llama 3.2                                      The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out).                               Meta                \n",
      "145528  cohereforai/aya-expanse                                   Aya Expanse                                    Aya Expanse advances the state-of-the-art in multilingual capabilities to help bridge language gaps with AI.                                                                                                          CohereForAI         \n",
      "127417  abdullahmeda/qwen2.5                                      Qwen2.5                                                                                                                                                                                                                                                              Abdullah Meda       \n",
      "146350  dasbro/xgb_model                                          XGB_model                                                                                                                                                                                                                                                            dasbro              \n",
      "121954  google/gemma-2-2b-jpn-it                                  Gemma 2 2b JPN IT                              Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.                                                             Google              \n",
      "141350  ultralytics/yolo11                                        Ultralytics YOLO11                             Ultralytics YOLO ğŸš€ for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.                                                                                 Ultralytics         \n",
      "  3301  google/gemma                                              Gemma                                          Gemma is a family of lightweight, open models built from the research and technology that Google used to create the Gemini models.                                                                                    Google              \n",
      "123481  takanashihumbert/qwen2.5                                  Qwen2.5                                                                                                                                                                                                                                                              Joseph              \n",
      "121030  metaresearch/llama-3.2-vision                             Llama 3.2 Vision                               The Llama 3.2-Vision collection of multimodal large language models (LLMs) is a collection of pretrained and instruction-tuned image reasoning generative models in 11B and 90B sizes (text + images in / text out).  Meta                \n",
      "  3533  keras/gemma                                               Gemma                                          Keras implementation of the Gemma model. This Keras 3 implementation will run on JAX, TensorFlow and PyTorch.                                                                                                         Keras               \n",
      "  1902  mistral-ai/mistral                                        Mistral                                        Mistral AI team is proud to release Mistral, the most powerful language model for its size to date.                                                                                                                   Mistral AI          \n",
      "141013  ultralytics/yolov8                                        Ultralytics YOLOv8                             Ultralytics YOLO ğŸš€ for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.                                                                                 Ultralytics         \n",
      "141044  huikang/qwen2.5                                           qwen2.5                                                                                                                                                                                                                                                              Tong Hui Kang       \n",
      " 91102  metaresearch/llama-3.1                                    Llama 3.1                                      The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models in 8B, 70B and 405B sizes (text in/text out).                        Meta                \n",
      " 78150  keras/gemma2                                              Gemma 2                                        Keras implementation of the Gemma 2 model. This Keras 3 implementation will run on JAX, TensorFlow and PyTorch.                                                                                                       Keras               \n",
      "128845  jonathanchan/baai                                         BAAI                                                                                                                                                                                                                                                                 Jonathan Chan       \n",
      "152800  ai-singapore/gemma2-9b-cpt-sea-lionv3-instruct            gemma2-9b-cpt-sea-lionv3-instruct              Gemma2 9B CPT SEA-LIONv3 Instruct                                                                                                                                                                                     AI Singapore        \n",
      " 76277  google/gemma-2                                            Gemma 2                                        Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.                                                             Google              \n",
      "142464  mehulbhattacharya/healthy-bleached-coral-reef-classifier  Coral Reef Health Image Classifier using YOLO  Detect Bleached or Healthy Coral Reef                                                                                                                                                                                 Mehul Bhattacharya  \n",
      "147213  darraghdog/qwen-qwen2.5-math-7b-instruct                  Qwen-Qwen2.5-Math-7B-Instruct                                                                                                                                                                                                                                        Darragh             \n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.model_list_cli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                                                deadline             category                reward  teamCount  userHasEntered  \n",
      "---------------------------------------------------------------------------------  -------------------  ---------------  -------------  ---------  --------------  \n",
      "https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-2      2025-04-01 23:59:00  Featured         2,117,152 Usd        412           False  \n",
      "https://www.kaggle.com/competitions/gemma-language-tuning                          2025-01-15 00:59:00  Analytics          150,000 Usd          0           False  \n",
      "https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting  2025-01-13 23:59:00  Featured           120,000 Usd       1327           False  \n",
      "https://www.kaggle.com/competitions/gemini-long-context                            2024-12-01 23:59:00  Analytics          100,000 Usd          0           False  \n",
      "https://www.kaggle.com/competitions/nfl-big-data-bowl-2025                         2025-01-08 23:59:00  Analytics          100,000 Usd          0           False  \n",
      "https://www.kaggle.com/competitions/czii-cryo-et-object-identification             2025-02-05 23:59:00  Featured            75,000 Usd         52           False  \n",
      "https://www.kaggle.com/competitions/child-mind-institute-problematic-internet-use  2024-12-19 23:59:00  Featured            60,000 Usd       2183           False  \n",
      "https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics      2024-12-12 23:59:00  Featured            55,000 Usd       1101           False  \n",
      "https://www.kaggle.com/competitions/um-game-playing-strength-of-mcts-variants      2024-12-02 23:59:00  Research            50,000 Usd       1319           False  \n",
      "https://www.kaggle.com/competitions/playground-series-s4e11                        2024-11-30 23:59:00  Playground                Swag       1054           False  \n",
      "https://www.kaggle.com/competitions/titanic                                        2030-01-01 00:00:00  Getting Started      Knowledge      16172           False  \n",
      "https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started      Knowledge       5590           False  \n",
      "https://www.kaggle.com/competitions/spaceship-titanic                              2030-01-01 00:00:00  Getting Started      Knowledge       1700           False  \n",
      "https://www.kaggle.com/competitions/digit-recognizer                               2030-01-01 00:00:00  Getting Started      Knowledge       1568           False  \n",
      "https://www.kaggle.com/competitions/nlp-getting-started                            2030-01-01 00:00:00  Getting Started      Knowledge       1012           False  \n",
      "https://www.kaggle.com/competitions/store-sales-time-series-forecasting            2030-06-30 23:59:00  Getting Started      Knowledge        776           False  \n",
      "https://www.kaggle.com/competitions/connectx                                       2030-01-01 00:00:00  Getting Started      Knowledge        203           False  \n",
      "https://www.kaggle.com/competitions/gan-getting-started                            2030-07-01 23:59:00  Getting Started      Knowledge         87           False  \n",
      "https://www.kaggle.com/competitions/contradictory-my-dear-watson                   2030-07-01 23:59:00  Getting Started      Knowledge         44           False  \n",
      "https://www.kaggle.com/competitions/tpu-getting-started                            2030-06-03 23:59:00  Getting Started      Knowledge         43           False  \n"
     ]
    }
   ],
   "source": [
    "! kaggle competitions list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can download datasets by using following command\n",
    "~~~\n",
    "! kaggle datasets download <name-of-dataset>\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/noxmoon/chinese-official-daily-news-since-2016\n",
      "License(s): unknown\n",
      "Downloading chinese-official-daily-news-since-2016.zip to c:\\Users\\wangs\\Dropbox\\å€‹äººç”¨\\æˆæ¥­\\åšå£«èª²ç¨‹\\äººæ–‡_2024_3Q\\DH\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/8.43M [00:00<?, ?B/s]\n",
      " 12%|â–ˆâ–        | 1.00M/8.43M [00:00<00:05, 1.34MB/s]\n",
      " 24%|â–ˆâ–ˆâ–       | 2.00M/8.43M [00:00<00:02, 2.42MB/s]\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 3.00M/8.43M [00:01<00:01, 3.05MB/s]\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4.00M/8.43M [00:02<00:02, 1.68MB/s]\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5.00M/8.43M [00:02<00:01, 1.93MB/s]\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 6.00M/8.43M [00:03<00:01, 2.09MB/s]\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 7.00M/8.43M [00:03<00:00, 2.19MB/s]\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 8.00M/8.43M [00:04<00:00, 2.18MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.43M/8.43M [00:04<00:00, 2.29MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.43M/8.43M [00:04<00:00, 2.13MB/s]\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download noxmoon/chinese-official-daily-news-since-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chinese-official-daily-news-since-2016.zipã‚’./extracted_dataã«è§£å‡ã—ã¾ã—ãŸã€‚\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
    "zip_file_path = \"chinese-official-daily-news-since-2016.zip\"\n",
    "extract_path = \"./extracted_data\"  # è§£å‡å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š\n",
    "\n",
    "# è§£å‡å…ˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£å‡\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(f\"{zip_file_path}ã‚’{extract_path}ã«è§£å‡ã—ã¾ã—ãŸã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part2 make a RAG using ChatGPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tag</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>è¯¦ç»†å…¨æ–‡</td>\n",
       "      <td>é™†å†›é¢†å¯¼æœºæ„ç«ç®­å†›æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿæˆç«‹å¤§ä¼šåœ¨äº¬ä¸¾è¡Œ ä¹ è¿‘å¹³å‘ä¸­å›½äººæ°‘è§£æ”¾å†›é™†å†›ç«ç®­å†›æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿ...</td>\n",
       "      <td>ä¸­å›½äººæ°‘è§£æ”¾å†›é™†å†›é¢†å¯¼æœºæ„ã€ä¸­å›½äººæ°‘è§£æ”¾å†›ç«ç®­å†›ã€ä¸­å›½äººæ°‘è§£æ”¾å†›æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿæˆç«‹å¤§ä¼š2015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>è¯¦ç»†å…¨æ–‡</td>\n",
       "      <td>ä¸­å¤®å†›å§”å°å‘ã€Šå…³äºæ·±åŒ–å›½é˜²å’Œå†›é˜Ÿæ”¹é©çš„æ„è§ã€‹</td>\n",
       "      <td>ç»ä¸­å¤®å†›å§”ä¸»å¸­ä¹ è¿‘å¹³æ‰¹å‡†ï¼Œä¸­å¤®å†›å§”è¿‘æ—¥å°å‘äº†ã€Šå…³äºæ·±åŒ–å›½é˜²å’Œå†›é˜Ÿæ”¹é©çš„æ„è§ã€‹ã€‚\\nã€Šæ„è§ã€‹å¼º...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>è¯¦ç»†å…¨æ–‡</td>\n",
       "      <td>ã€Šä¹ è¿‘å¹³å…³äºä¸¥æ˜å…šçš„çºªå¾‹å’Œè§„çŸ©è®ºè¿°æ‘˜ç¼–ã€‹å‡ºç‰ˆå‘è¡Œ</td>\n",
       "      <td>ç”±ä¸­å…±ä¸­å¤®çºªå¾‹æ£€æŸ¥å§”å‘˜ä¼šã€ä¸­å…±ä¸­å¤®æ–‡çŒ®ç ”ç©¶å®¤ç¼–è¾‘çš„ã€Šä¹ è¿‘å¹³å…³äºä¸¥æ˜å…šçš„çºªå¾‹å’Œè§„çŸ©è®ºè¿°æ‘˜ç¼–ã€‹ä¸€...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>è¯¦ç»†å…¨æ–‡</td>\n",
       "      <td>ä»¥å®é™…è¡ŒåŠ¨å‘å…šä¸­å¤®çœ‹é½ å‘é«˜æ ‡å‡†åŠªåŠ›</td>\n",
       "      <td>å¹¿å¤§å…šå‘˜å¹²éƒ¨æ­£åœ¨ç§¯æå­¦ä¹ ä¹ è¿‘å¹³æ€»ä¹¦è®°åœ¨ä¸­å¤®æ”¿æ²»å±€ä¸“é¢˜æ°‘ä¸»ç”Ÿæ´»ä¼šä¸Šçš„é‡è¦è®²è¯ã€‚å¤§å®¶çº·çº·è¡¨ç¤ºè¦æŠŠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>è¯¦ç»†å…¨æ–‡</td>\n",
       "      <td>ã€å¹´ç»ˆç‰¹ç¨¿ã€‘å…³é”®ä¹‹å¹´ æ”¹é©æŒºè¿›æ·±æ°´åŒº</td>\n",
       "      <td>åˆšåˆšè¿‡å»çš„2015å¹´ï¼Œæ˜¯å…¨é¢æ·±åŒ–æ”¹é©çš„å…³é”®ä¹‹å¹´ã€‚æ”¹é©é›†ä¸­å‘åŠ›åœ¨åˆ¶çº¦ç»æµç¤¾ä¼šå‘å±•çš„æ·±å±‚æ¬¡çŸ›ç›¾ï¼Œ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   tag                                           headline  \\\n",
       "0  2016-01-01  è¯¦ç»†å…¨æ–‡  é™†å†›é¢†å¯¼æœºæ„ç«ç®­å†›æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿæˆç«‹å¤§ä¼šåœ¨äº¬ä¸¾è¡Œ ä¹ è¿‘å¹³å‘ä¸­å›½äººæ°‘è§£æ”¾å†›é™†å†›ç«ç®­å†›æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿ...   \n",
       "1  2016-01-01  è¯¦ç»†å…¨æ–‡                             ä¸­å¤®å†›å§”å°å‘ã€Šå…³äºæ·±åŒ–å›½é˜²å’Œå†›é˜Ÿæ”¹é©çš„æ„è§ã€‹   \n",
       "2  2016-01-01  è¯¦ç»†å…¨æ–‡                           ã€Šä¹ è¿‘å¹³å…³äºä¸¥æ˜å…šçš„çºªå¾‹å’Œè§„çŸ©è®ºè¿°æ‘˜ç¼–ã€‹å‡ºç‰ˆå‘è¡Œ   \n",
       "3  2016-01-01  è¯¦ç»†å…¨æ–‡                                 ä»¥å®é™…è¡ŒåŠ¨å‘å…šä¸­å¤®çœ‹é½ å‘é«˜æ ‡å‡†åŠªåŠ›   \n",
       "4  2016-01-01  è¯¦ç»†å…¨æ–‡                                 ã€å¹´ç»ˆç‰¹ç¨¿ã€‘å…³é”®ä¹‹å¹´ æ”¹é©æŒºè¿›æ·±æ°´åŒº   \n",
       "\n",
       "                                             content  \n",
       "0  ä¸­å›½äººæ°‘è§£æ”¾å†›é™†å†›é¢†å¯¼æœºæ„ã€ä¸­å›½äººæ°‘è§£æ”¾å†›ç«ç®­å†›ã€ä¸­å›½äººæ°‘è§£æ”¾å†›æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿæˆç«‹å¤§ä¼š2015...  \n",
       "1  ç»ä¸­å¤®å†›å§”ä¸»å¸­ä¹ è¿‘å¹³æ‰¹å‡†ï¼Œä¸­å¤®å†›å§”è¿‘æ—¥å°å‘äº†ã€Šå…³äºæ·±åŒ–å›½é˜²å’Œå†›é˜Ÿæ”¹é©çš„æ„è§ã€‹ã€‚\\nã€Šæ„è§ã€‹å¼º...  \n",
       "2  ç”±ä¸­å…±ä¸­å¤®çºªå¾‹æ£€æŸ¥å§”å‘˜ä¼šã€ä¸­å…±ä¸­å¤®æ–‡çŒ®ç ”ç©¶å®¤ç¼–è¾‘çš„ã€Šä¹ è¿‘å¹³å…³äºä¸¥æ˜å…šçš„çºªå¾‹å’Œè§„çŸ©è®ºè¿°æ‘˜ç¼–ã€‹ä¸€...  \n",
       "3  å¹¿å¤§å…šå‘˜å¹²éƒ¨æ­£åœ¨ç§¯æå­¦ä¹ ä¹ è¿‘å¹³æ€»ä¹¦è®°åœ¨ä¸­å¤®æ”¿æ²»å±€ä¸“é¢˜æ°‘ä¸»ç”Ÿæ´»ä¼šä¸Šçš„é‡è¦è®²è¯ã€‚å¤§å®¶çº·çº·è¡¨ç¤ºè¦æŠŠ...  \n",
       "4  åˆšåˆšè¿‡å»çš„2015å¹´ï¼Œæ˜¯å…¨é¢æ·±åŒ–æ”¹é©çš„å…³é”®ä¹‹å¹´ã€‚æ”¹é©é›†ä¸­å‘åŠ›åœ¨åˆ¶çº¦ç»æµç¤¾ä¼šå‘å±•çš„æ·±å±‚æ¬¡çŸ›ç›¾ï¼Œ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "file_path = 'extracted_data/chinese_news.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# æœ€åˆã®æ•°è¡Œã‚’ç¢ºèª\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ‡ãƒ¼ã‚¿ã«ã¯ä»¥ä¸‹ã®åˆ—ãŒã‚ã‚Šã¾ã™ï¼š\n",
    "\n",
    "- date: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æ—¥ä»˜\n",
    "- tag: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚¿ã‚°\n",
    "- headline: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦‹å‡ºã—\n",
    "- content: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å†…å®¹ï¼ˆã“ã®åˆ—ã‚’ä¸»ã«ä½¿ç”¨ï¼‰\n",
    "\n",
    "æ¬¡ã«ã€contentåˆ—ã‚’ä½¿ç”¨ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã‚’è¡Œã„ã€RAGãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³éƒ¨åˆ†ã‚’ä½œæˆã—ã¾ã™ã€‚faissã‚’ä½¿ã£ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã—ã€transformersã‚’ä½¿ã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¾ã™ã€‚ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wangs\\anaconda3\\envs\\DH\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã‚µãƒ³ãƒ—ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸã€‚\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®æº–å‚™ï¼ˆSentence Transformersã‚’ä½¿ç”¨ï¼‰\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®é–¢æ•°\n",
    "def embed_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings[0].numpy()\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å–å¾—\n",
    "sample_data = data['headline'].sample(5000, random_state=1)  # ãƒ©ãƒ³ãƒ€ãƒ ã«10ä»¶ã‚’æŠ½å‡º\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã‚’è©¦è¡Œ\n",
    "try:\n",
    "    sample_embeddings = np.array([embed_text(text) for text in sample_data])\n",
    "    sample_index = faiss.IndexFlatL2(sample_embeddings.shape[1])\n",
    "    sample_index.add(sample_embeddings)\n",
    "    print(\"ã‚µãƒ³ãƒ—ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸã€‚\")\n",
    "except Exception as e:\n",
    "    print(\"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query, k=3):\n",
    "    # è³ªå•ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "    query_vector = embed_text(query).reshape(1, -1)\n",
    "    distances, indices = sample_index.search(query_vector, k)  # kã¯å–å¾—ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°\n",
    "    return [sample_data.iloc[i] for i in indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"\"\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "def generate_answer(query, retrieved_docs):\n",
    "    context = \"\\n\".join(retrieved_docs)\n",
    "    prompt = f\"ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\\n{context}\\n\\nè³ªå•: {query}\\nç­”ãˆ:\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1500\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”Ÿæˆã•ã‚ŒãŸç­”ãˆ: 2016å¹´1æœˆ1æ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ã‚ˆã‚Œã°ã€åŒ—äº¬å¸‚ã¯ã€Œåä¸‰äº”ã€è§„åˆ’ã‚’ç™ºè¡¨ã—ã€2020å¹´ã¾ã§ã«åŒ—äº¬åŸå…­åŒºã®å¸¸ä½äººå£ã‚’2014å¹´ã®åŸºæº–ã‹ã‚‰ç´„15%æ¸›å°‘ã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚ã“ã®å¯¾ç­–ã«ã¯éé¦–éƒ½æ©Ÿèƒ½ã®èª¿æ•´ã¨äººå£ã®æœ€é©åŒ–ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n",
      "\n",
      "ã¾ãŸã€2015å¹´æœ«ã¾ã§ã«å…¨å›½ã§783ä¸‡å¥—ã®ä¿éšœæ€§å®‰å±…å·¥ç¨‹ãŒé–‹å·¥ã—ã€772ä¸‡å¥—ãŒåŸºæœ¬çš„ã«å®Œæˆã—ã¾ã—ãŸã€‚ã“ã‚Œã¯2015å¹´åº¦ã®ç›®æ¨™ã‚’ä¸Šå›ã‚‹é”æˆã§ã™ã€‚ç‰¹ã«æ£šæˆ¸åŒºæ”¹é€ ã«é–¢ã—ã¦ã¯601ä¸‡å¥—ãŒé–‹å·¥ã—ã€å¹´åº¦\n"
     ]
    }
   ],
   "source": [
    "# è³ªå•ã‚’è¨­å®šã—ã€æ¤œç´¢ã¨ç”Ÿæˆã‚’è¡Œã†\n",
    "query = \"2016-01-01ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„\"\n",
    "retrieved_docs = retrieve_documents(query)\n",
    "answer = generate_answer(query, retrieved_docs)\n",
    "\n",
    "print(\"ç”Ÿæˆã•ã‚ŒãŸç­”ãˆ:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”Ÿæˆã•ã‚ŒãŸç­”ãˆ: æä¾›ã•ã‚ŒãŸæƒ…å ±ã«ã¯åŒ—äº¬ãƒ€ãƒƒã‚¯ã«é–¢ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä»£ã‚ã‚Šã«ã€ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ï¼š\n",
      "\n",
      "1. åŒ—äº¬ã®é‰„é“è­¦å¯ŸãŒå½ãƒã‚±ãƒƒãƒˆã®è£½é€ ãŠã‚ˆã³è²©å£²æ‹ ç‚¹ã‚’æœç´¢ã—ã€å£Šæ»…ã•ã›ã¾ã—ãŸã€‚\n",
      "2. ä¹ è¿‘å¹³ï¼ˆã‚·ãƒ¼ãƒ»ãƒãƒ³ãƒ”ãƒ³ã‚°ï¼‰å›½å®¶ä¸»å¸­ãŒåŒ—äº¬å¸‚ã®å…«ä¸€å­¦æ ¡ã‚’è¨ªå•ã—ã€æ•™è‚²æ–¹é‡ã®å…¨é¢çš„ãªå®Ÿæ–½ã‚’å¼·èª¿ã—ã€ä¸­å›½ã®åŸºç¤æ•™è‚²ã‚’å‘ä¸Šã•ã›ã‚‹åŠªåŠ›ã‚’å‘¼ã³ã‹ã‘ã¾ã—ãŸã€‚\n",
      "3. åŒ—äº¬å¸‚ã¯éé¦–éƒ½æ©Ÿèƒ½ã®è§£æ¶ˆã‚’é€²ã‚ã¦ãŠã‚Šã€ç”£æ¥­ã®å¢—æ¸›ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
      "\n",
      "åŒ—äº¬ãƒ€ãƒƒã‚¯ã«é–¢ã™ã‚‹æƒ…å ±ãŒå¿…è¦ã§ã‚ã‚Œã°ã€åˆ¥ã®ã‚½ãƒ¼ã‚¹ã‚’å‚ç…§ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n"
     ]
    }
   ],
   "source": [
    "# è³ªå•ã‚’è¨­å®šã—ã€æ¤œç´¢ã¨ç”Ÿæˆã‚’è¡Œã†\n",
    "query = \"åŒ—äº¬ãƒ€ãƒƒã‚¯ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„\"\n",
    "retrieved_docs = retrieve_documents(query)\n",
    "answer = generate_answer(query, retrieved_docs)\n",
    "\n",
    "print(\"ç”Ÿæˆã•ã‚ŒãŸç­”ãˆ:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€æƒ…å ±æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«é–¢é€£ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’æ¤œç´¢ã™ã‚‹ä»•çµ„ã¿ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚è³ªå•ã‹ã‚‰é¡ä¼¼ã®æ–‡æ›¸ã‚’æ¤œç´¢ã—ã¦å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDFãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å†è¨­å®šï¼šæ¬¡å…ƒæ•°ã‚’å‰Šæ¸›\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # æ¬¡å…ƒã‚’5000 -> 1000ã«å‰Šæ¸›\n",
    "tfidf_matrix = vectorizer.fit_transform(data)\n",
    "\n",
    "# kè¿‘å‚æ³•ã‚’ä½¿ã£ãŸã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã§ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ\n",
    "knn_index = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn_index.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'headline': 'é™†å†›é¢†å¯¼æœºæ„ç«ç®­å†›æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿæˆç«‹å¤§ä¼šåœ¨äº¬ä¸¾è¡Œ ä¹ è¿‘å¹³å‘ä¸­å›½äººæ°‘è§£æ”¾å†›é™†å†›ç«ç®­å†›æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿæˆäºˆå†›æ——å¹¶è‡´è®­è¯',\n",
       "  'content': 'ä¸­å›½äººæ°‘è§£æ”¾å†›é™†å†›é¢†å¯¼æœºæ„ã€ä¸­å›½äººæ°‘è§£æ”¾å†›ç«ç®­å†›ã€ä¸­å›½äººæ°‘è§£æ”¾å†›æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿæˆç«‹å¤§ä¼š2015å¹´12æœˆ31æ—¥åœ¨å…«ä¸€å¤§æ¥¼éš†é‡ä¸¾è¡Œã€‚ä¸­å…±ä¸­å¤®æ€»ä¹¦è®°ã€å›½å®¶ä¸»å¸­ã€ä¸­å¤®å†›å§”ä¸»å¸­ä¹ è¿‘å¹³å‘é™†å†›ã€ç«ç®­å†›ã€æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿæˆäºˆå†›æ——å¹¶è‡´è®­è¯ï¼Œä»£è¡¨å…šä¸­å¤®å’Œä¸­å¤®å†›å§”å‘åŒå¿—ä»¬ã€å‘å…¨å†›éƒ¨é˜Ÿè‡´ä»¥çƒ­çƒˆç¥è´ºï¼Œå¼ºè°ƒè¦åšæŒä»¥å…šåœ¨æ–°å½¢åŠ¿ä¸‹çš„å¼ºå†›ç›®æ ‡ä¸ºå¼•é¢†ï¼Œæ·±å…¥è´¯å½»æ–°å½¢åŠ¿ä¸‹å†›äº‹æˆ˜ç•¥æ–¹é’ˆï¼Œå…¨é¢å®æ–½æ”¹é©å¼ºå†›æˆ˜ç•¥ï¼Œåšå®šä¸ç§»èµ°ä¸­å›½ç‰¹è‰²å¼ºå†›ä¹‹è·¯ï¼Œæ—¶åˆ»å¬ä»å…šå’Œäººæ°‘å¬å”¤ï¼Œå¿ å®å±¥è¡Œå…šå’Œäººæ°‘èµ‹äºˆçš„ç¥åœ£ä½¿å‘½ï¼Œä¸ºå®ç°ä¸­å›½æ¢¦å¼ºå†›æ¢¦ä½œå‡ºæ–°çš„æ›´å¤§çš„è´¡çŒ®ã€‚\\nä¸‹åˆ4æ—¶ï¼Œæˆç«‹å¤§ä¼šå¼€å§‹ï¼Œå…¨åœºé«˜å”±å›½æ­Œã€‚ä»ªä»—ç¤¼å…µæŠ¤å«ç€é²œè‰³å†›æ——ï¼Œæ­£æ­¥è¡Œè¿›åˆ°ä¸»å¸­å°å‰ã€‚ä¹ è¿‘å¹³å°†å†›æ——éƒ‘é‡æˆäºˆé™†å†›å¸ä»¤å‘˜æä½œæˆã€æ”¿æ²»å§”å‘˜åˆ˜é›·ï¼Œç«ç®­å†›å¸ä»¤å‘˜é­å‡¤å’Œæ”¿æ²»å§”å‘˜ç‹å®¶èƒœï¼Œæˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿå¸ä»¤å‘˜é«˜æ´¥ã€æ”¿æ²»å§”å‘˜åˆ˜ç¦è¿ã€‚é™†å†›ã€ç«ç®­å†›ã€æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿä¸»è¦é¢†å¯¼ï¼Œå†›å®¹ä¸¥æ•´ã€ç²¾ç¥æŠ–æ“ï¼Œå‘ä¹ è¿‘å¹³æ•¬ç¤¼ï¼Œä»ä¹ è¿‘å¹³æ‰‹ä¸­æ¥è¿‡å†›æ——ã€‚å…¨åœºå®˜å…µå‘å†›æ——æ•¬ç¤¼ã€‚\\næˆæ——ä»ªå¼åï¼Œä¹ è¿‘å¹³è‡´è®­è¯ã€‚ä»–æŒ‡å‡ºï¼šâ€œæˆç«‹é™†å†›é¢†å¯¼æœºæ„ã€ç«ç®­å†›ã€æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿï¼Œæ˜¯å…šä¸­å¤®å’Œä¸­å¤®å†›å§”ç€çœ¼å®ç°ä¸­å›½æ¢¦å¼ºå†›æ¢¦ä½œå‡ºçš„é‡å¤§å†³ç­–ï¼Œæ˜¯æ„å»ºä¸­å›½ç‰¹è‰²ç°ä»£å†›äº‹åŠ›é‡ä½“ç³»çš„æˆ˜ç•¥ä¸¾æªï¼Œå¿…å°†æˆä¸ºæˆ‘å†›ç°ä»£åŒ–å»ºè®¾çš„ä¸€ä¸ªé‡è¦é‡Œç¨‹ç¢‘ï¼Œè½½å…¥äººæ°‘å†›é˜Ÿå²å†Œã€‚â€\\nä¹ è¿‘å¹³å¼ºè°ƒï¼Œé™†å†›æ˜¯å…šæœ€æ—©å»ºç«‹å’Œé¢†å¯¼çš„æ­¦è£…åŠ›é‡ï¼Œå†å²æ‚ ä¹…ï¼Œæ•¢æ‰“å–„æˆ˜ï¼Œæˆ˜åŠŸå“è‘—ï¼Œä¸ºå…šå’Œäººæ°‘å»ºç«‹äº†ä¸æœ½åŠŸå‹‹ã€‚é™†å†›å¯¹ç»´æŠ¤å›½å®¶ä¸»æƒã€å®‰å…¨å’Œå‘å±•åˆ©ç›Šå…·æœ‰ä¸å¯æ›¿ä»£çš„ä½œç”¨ã€‚é™†å†›å…¨ä½“å®˜å…µè¦å¼˜æ‰¬é™†å†›å…‰è£ä¼ ç»Ÿå’Œä¼˜è‰¯ä½œé£ï¼Œé€‚åº”ä¿¡æ¯åŒ–æ—¶ä»£é™†å†›å»ºè®¾æ¨¡å¼å’Œè¿ç”¨æ–¹å¼çš„æ·±åˆ»å˜åŒ–ï¼Œæ¢ç´¢é™†å†›å‘å±•ç‰¹ç‚¹å’Œè§„å¾‹ï¼ŒæŒ‰ç…§æœºåŠ¨ä½œæˆ˜ã€ç«‹ä½“æ”»é˜²çš„æˆ˜ç•¥è¦æ±‚ï¼ŒåŠ å¼ºé¡¶å±‚è®¾è®¡å’Œé¢†å¯¼ç®¡ç†ï¼Œä¼˜åŒ–åŠ›é‡ç»“æ„å’Œéƒ¨é˜Ÿç¼–æˆï¼ŒåŠ å¿«å®ç°åŒºåŸŸé˜²å«å‹å‘å…¨åŸŸä½œæˆ˜å‹è½¬å˜ï¼ŒåŠªåŠ›å»ºè®¾ä¸€æ”¯å¼ºå¤§çš„ç°ä»£åŒ–æ–°å‹é™†å†›ã€‚\\nä¹ è¿‘å¹³å¼ºè°ƒï¼Œç«ç®­å†›æ˜¯æˆ‘å›½æˆ˜ç•¥å¨æ…‘çš„æ ¸å¿ƒåŠ›é‡ï¼Œæ˜¯æˆ‘å›½å¤§å›½åœ°ä½çš„æˆ˜ç•¥æ”¯æ’‘ï¼Œæ˜¯ç»´æŠ¤å›½å®¶å®‰å…¨çš„é‡è¦åŸºçŸ³ã€‚ç«ç®­å†›å…¨ä½“å®˜å…µè¦æŠŠæ¡ç«ç®­å†›çš„èŒèƒ½å®šä½å’Œä½¿å‘½ä»»åŠ¡ï¼ŒæŒ‰ç…§æ ¸å¸¸å…¼å¤‡ã€å…¨åŸŸæ…‘æˆ˜çš„æˆ˜ç•¥è¦æ±‚ï¼Œå¢å¼ºå¯ä¿¡å¯é çš„æ ¸å¨æ…‘å’Œæ ¸åå‡»èƒ½åŠ›ï¼ŒåŠ å¼ºä¸­è¿œç¨‹ç²¾ç¡®æ‰“å‡»åŠ›é‡å»ºè®¾ï¼Œå¢å¼ºæˆ˜ç•¥åˆ¶è¡¡èƒ½åŠ›ï¼ŒåŠªåŠ›å»ºè®¾ä¸€æ”¯å¼ºå¤§çš„ç°ä»£åŒ–ç«ç®­å†›ã€‚\\nä¹ è¿‘å¹³å¼ºè°ƒï¼Œæˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿæ˜¯ç»´æŠ¤å›½å®¶å®‰å…¨çš„æ–°å‹ä½œæˆ˜åŠ›é‡ï¼Œæ˜¯æˆ‘å†›æ–°è´¨ä½œæˆ˜èƒ½åŠ›çš„é‡è¦å¢é•¿ç‚¹ã€‚æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿå…¨ä½“å®˜å…µè¦åšæŒä½“ç³»èåˆã€å†›æ°‘èåˆï¼ŒåŠªåŠ›åœ¨å…³é”®é¢†åŸŸå®ç°è·¨è¶Šå‘å±•ï¼Œé«˜æ ‡å‡†é«˜èµ·ç‚¹æ¨è¿›æ–°å‹ä½œæˆ˜åŠ›é‡åŠ é€Ÿå‘å±•ã€ä¸€ä½“å‘å±•ï¼ŒåŠªåŠ›å»ºè®¾ä¸€æ”¯å¼ºå¤§çš„ç°ä»£åŒ–æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿã€‚\\nä¹ è¿‘å¹³å¼ºè°ƒï¼šâ€œä½ ä»¬è¦åšæŒä»¥å…šåœ¨æ–°å½¢åŠ¿ä¸‹çš„å¼ºå†›ç›®æ ‡ä¸ºå¼•é¢†ï¼Œæ·±å…¥è´¯å½»æ–°å½¢åŠ¿ä¸‹å†›äº‹æˆ˜ç•¥æ–¹é’ˆï¼Œå…¨é¢å®æ–½æ”¹é©å¼ºå†›æˆ˜ç•¥ï¼Œåšå®šä¸ç§»èµ°ä¸­å›½ç‰¹è‰²å¼ºå†›ä¹‹è·¯ï¼Œæ—¶åˆ»å¬ä»å…šå’Œäººæ°‘çš„å¬å”¤ï¼Œå¿ è¯šå±¥è¡Œå…šå’Œäººæ°‘èµ‹äºˆçš„ç¥åœ£ä½¿å‘½ï¼Œä¸ºå®ç°ä¸­å›½æ¢¦å¼ºå†›æ¢¦ä½œå‡ºæ–°çš„æ›´å¤§çš„è´¡çŒ®ã€‚â€\\nåˆ˜é›·ã€ç‹å®¶èƒœã€åˆ˜ç¦è¿åˆ†åˆ«ä»£è¡¨é™†å†›ã€ç«ç®­å†›ã€æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿå‘è¨€ï¼Œä¸€è‡´è¡¨ç¤ºï¼Œåšå†³è´¯å½»ä¹ ä¸»å¸­è®­è¯ï¼Œä»»ä½•æ—¶å€™ä»»ä½•æƒ…å†µä¸‹éƒ½åšå†³å¬ä»å…šä¸­å¤®ã€ä¸­å¤®å†›å§”å’Œä¹ ä¸»å¸­æŒ‡æŒ¥ï¼Œç‰¢è®°èŒè´£ä½¿å‘½ï¼Œå¿ è¯šå±¥èŒå°½è´£ï¼Œå¸¦é¢†éƒ¨é˜Ÿåœ†æ»¡å®Œæˆå„é¡¹ä»»åŠ¡ã€‚\\næˆç«‹å¤§ä¼šä¸Šï¼Œä¸­å…±ä¸­å¤®æ”¿æ²»å±€å§”å‘˜ã€ä¸­å¤®å†›å§”å‰¯ä¸»å¸­èŒƒé•¿é¾™å®£è¯»äº†ä¹ è¿‘å¹³ä¸»å¸­ç­¾å‘çš„ä¸­å¤®å†›å§”å…³äºç»„å»ºé™†å†›é¢†å¯¼æœºæ„ã€ç«ç®­å†›ã€æˆ˜ç•¥æ”¯æ´éƒ¨é˜ŸåŠå…¶é¢†å¯¼ç­å­æˆå‘˜ä»»èŒå‘½ä»¤å’Œå†³å®šã€‚ä¸­å…±ä¸­å¤®æ”¿æ²»å±€å§”å‘˜ã€ä¸­å¤®å†›å§”å‰¯ä¸»å¸­è®¸å…¶äº®ä¸»æŒå¤§ä¼šã€‚\\nå¤§ä¼šåœ¨å˜¹äº®çš„å†›æ­Œå£°ä¸­ç»“æŸã€‚ä¹‹åï¼Œä¹ è¿‘å¹³äº²åˆ‡æ¥è§äº†é™†å†›ã€ç«ç®­å†›ã€æˆ˜ç•¥æ”¯æ´éƒ¨é˜Ÿé¢†å¯¼ç­å­æˆå‘˜ï¼Œå¹¶åŒå¤§å®¶åˆå½±ç•™å¿µã€‚\\nä¸­å¤®å†›å§”å§”å‘˜å¸¸ä¸‡å…¨ã€æˆ¿å³°è¾‰ã€å¼ é˜³ã€èµµå…‹çŸ³ã€å¼ åˆä¾ ã€å´èƒœåˆ©ã€é©¬æ™“å¤©å‡ºå¸­å¤§ä¼šã€‚å››æ€»éƒ¨ã€é©»äº¬å„å¤§å•ä½å’Œå†›å§”åŠå…¬å…é¢†å¯¼å‚åŠ å¤§ä¼šã€‚\\n'},\n",
       " {'headline': 'ä¸­å¤®å†›å§”å°å‘ã€Šå…³äºæ·±åŒ–å›½é˜²å’Œå†›é˜Ÿæ”¹é©çš„æ„è§ã€‹',\n",
       "  'content': 'ç»ä¸­å¤®å†›å§”ä¸»å¸­ä¹ è¿‘å¹³æ‰¹å‡†ï¼Œä¸­å¤®å†›å§”è¿‘æ—¥å°å‘äº†ã€Šå…³äºæ·±åŒ–å›½é˜²å’Œå†›é˜Ÿæ”¹é©çš„æ„è§ã€‹ã€‚\\nã€Šæ„è§ã€‹å¼ºè°ƒï¼Œå…šçš„åå…«å¤§ä»¥æ¥ï¼Œå…šä¸­å¤®ã€ä¸­å¤®å†›å§”å’Œä¹ ä¸»å¸­å›´ç»•å®ç°å¼ºå†›ç›®æ ‡ï¼Œç»Ÿç­¹å†›é˜Ÿé©å‘½åŒ–ã€ç°ä»£åŒ–ã€æ­£è§„åŒ–å»ºè®¾ï¼Œç»Ÿç­¹å†›äº‹åŠ›é‡å»ºè®¾å’Œè¿ç”¨ï¼Œç»Ÿç­¹ç»æµå»ºè®¾å’Œå›½é˜²å»ºè®¾ï¼Œåˆ¶å®šæ–°å½¢åŠ¿ä¸‹å†›äº‹æˆ˜ç•¥æ–¹é’ˆï¼Œæå‡ºä¸€ç³»åˆ—é‡å¤§æ–¹é’ˆåŸåˆ™ï¼Œä½œå‡ºä¸€ç³»åˆ—é‡å¤§å†³ç­–éƒ¨ç½²ã€‚è´¯å½»è½å®å…šä¸­å¤®ã€ä¸­å¤®å†›å§”å’Œä¹ ä¸»å¸­çš„é‡å¤§æˆ˜ç•¥è°‹åˆ’å’Œæˆ˜ç•¥è®¾è®¡ï¼Œå¿…é¡»æ·±åŒ–å›½é˜²å’Œå†›é˜Ÿæ”¹é©ï¼Œå…¨é¢å®æ–½æ”¹é©å¼ºå†›æˆ˜ç•¥ï¼Œåšå®šä¸ç§»èµ°ä¸­å›½ç‰¹è‰²å¼ºå†›ä¹‹è·¯ã€‚\\nã€Šæ„è§ã€‹æŒ‡å‡ºï¼Œæ·±åŒ–å›½é˜²å’Œå†›é˜Ÿæ”¹é©çš„æŒ‡å¯¼æ€æƒ³æ˜¯ï¼Œæ·±å…¥è´¯å½»å…šçš„åå…«å¤§å’Œåå…«å±Šä¸‰ä¸­ã€å››ä¸­ã€äº”ä¸­å…¨ä¼šç²¾ç¥ï¼Œä»¥é©¬å…‹æ€åˆ—å®ä¸»ä¹‰ã€æ¯›æ³½ä¸œæ€æƒ³ã€é‚“å°å¹³ç†è®ºã€â€œä¸‰ä¸ªä»£è¡¨â€é‡è¦æ€æƒ³ã€ç§‘å­¦å‘å±•è§‚ä¸ºæŒ‡å¯¼ï¼Œæ·±å…¥è´¯å½»ä¹ ä¸»å¸­ç³»åˆ—é‡è¦è®²è¯ç²¾ç¥ç‰¹åˆ«æ˜¯å›½é˜²å’Œå†›é˜Ÿå»ºè®¾é‡è¦è®ºè¿°ï¼ŒæŒ‰ç…§â€œå››ä¸ªå…¨é¢â€æˆ˜ç•¥å¸ƒå±€è¦æ±‚ï¼Œä»¥å…šåœ¨æ–°å½¢åŠ¿ä¸‹çš„å¼ºå†›ç›®æ ‡ä¸ºå¼•é¢†ï¼Œè´¯å½»æ–°å½¢åŠ¿ä¸‹å†›äº‹æˆ˜ç•¥æ–¹é’ˆï¼Œå…¨é¢å®æ–½æ”¹é©å¼ºå†›æˆ˜ç•¥ï¼Œç€åŠ›è§£å†³åˆ¶çº¦å›½é˜²å’Œå†›é˜Ÿå‘å±•çš„ä½“åˆ¶æ€§éšœç¢ã€ç»“æ„æ€§çŸ›ç›¾ã€æ”¿ç­–æ€§é—®é¢˜ï¼Œæ¨è¿›å†›é˜Ÿç»„ç»‡å½¢æ€ç°ä»£åŒ–ï¼Œè¿›ä¸€æ­¥è§£æ”¾å’Œå‘å±•æˆ˜æ–—åŠ›ï¼Œè¿›ä¸€æ­¥è§£æ”¾å’Œå¢å¼ºå†›é˜Ÿæ´»åŠ›ï¼Œå»ºè®¾åŒæˆ‘å›½å›½é™…åœ°ä½ç›¸ç§°ã€åŒå›½å®¶å®‰å…¨å’Œå‘å±•åˆ©ç›Šç›¸é€‚åº”çš„å·©å›ºå›½é˜²å’Œå¼ºå¤§å†›é˜Ÿï¼Œä¸ºå®ç°â€œä¸¤ä¸ªä¸€ç™¾å¹´â€å¥‹æ–—ç›®æ ‡ã€å®ç°ä¸­åæ°‘æ—ä¼Ÿå¤§å¤å…´çš„ä¸­å›½æ¢¦æä¾›åšå¼ºåŠ›é‡ä¿è¯ã€‚\\nã€Šæ„è§ã€‹å¼ºè°ƒï¼Œæ·±åŒ–å›½é˜²å’Œå†›é˜Ÿæ”¹é©è¦åšæŒä»¥ä¸‹åŸºæœ¬åŸåˆ™ï¼šåšæŒæ­£ç¡®æ”¿æ²»æ–¹å‘ï¼ŒåšæŒå‘æ‰“ä»—èšç„¦ï¼ŒåšæŒåˆ›æ–°é©±åŠ¨ï¼ŒåšæŒä½“ç³»è®¾è®¡ï¼ŒåšæŒæ³•æ²»æ€ç»´ï¼ŒåšæŒç§¯æç¨³å¦¥ã€‚\\nã€Šæ„è§ã€‹æŒ‡å‡ºï¼Œæ·±åŒ–å›½é˜²å’Œå†›é˜Ÿæ”¹é©æ€»ä½“ç›®æ ‡æ˜¯ï¼Œç‰¢ç‰¢æŠŠæ¡â€œå†›å§”ç®¡æ€»ã€æˆ˜åŒºä¸»æˆ˜ã€å†›ç§ä¸»å»ºâ€çš„åŸåˆ™ï¼Œä»¥é¢†å¯¼ç®¡ç†ä½“åˆ¶ã€è”åˆä½œæˆ˜æŒ‡æŒ¥ä½“åˆ¶æ”¹é©ä¸ºé‡ç‚¹ï¼Œåè°ƒæ¨è¿›è§„æ¨¡ç»“æ„ã€æ”¿ç­–åˆ¶åº¦å’Œå†›æ°‘èåˆæ·±åº¦å‘å±•æ”¹é©ã€‚2020å¹´å‰ï¼Œåœ¨é¢†å¯¼ç®¡ç†ä½“åˆ¶ã€è”åˆä½œæˆ˜æŒ‡æŒ¥ä½“åˆ¶æ”¹é©ä¸Šå–å¾—çªç ´æ€§è¿›å±•ï¼Œåœ¨ä¼˜åŒ–è§„æ¨¡ç»“æ„ã€å®Œå–„æ”¿ç­–åˆ¶åº¦ã€æ¨åŠ¨å†›æ°‘èåˆæ·±åº¦å‘å±•ç­‰æ–¹é¢æ”¹é©ä¸Šå–å¾—é‡è¦æˆæœï¼ŒåŠªåŠ›æ„å»ºèƒ½å¤Ÿæ‰“èµ¢ä¿¡æ¯åŒ–æˆ˜äº‰ã€æœ‰æ•ˆå±¥è¡Œä½¿å‘½ä»»åŠ¡çš„ä¸­å›½ç‰¹è‰²ç°ä»£å†›äº‹åŠ›é‡ä½“ç³»ï¼Œè¿›ä¸€æ­¥å®Œå–„ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰å†›äº‹åˆ¶åº¦ã€‚\\nã€Šæ„è§ã€‹æ˜ç¡®äº†é¢†å¯¼ç®¡ç†ä½“åˆ¶ã€è”åˆä½œæˆ˜æŒ‡æŒ¥ä½“åˆ¶ã€å†›é˜Ÿè§„æ¨¡ç»“æ„ã€éƒ¨é˜Ÿç¼–æˆã€æ–°å‹å†›äº‹äººæ‰åŸ¹å…»ã€æ”¿ç­–åˆ¶åº¦ã€å†›æ°‘èåˆå‘å±•ã€æ­¦è£…è­¦å¯Ÿéƒ¨é˜ŸæŒ‡æŒ¥ç®¡ç†ä½“åˆ¶å’ŒåŠ›é‡ç»“æ„ã€å†›äº‹æ³•æ²»ä½“ç³»ç­‰æ–¹é¢çš„ä¸»è¦ä»»åŠ¡ã€‚\\nã€Šæ„è§ã€‹å¼ºè°ƒï¼Œæ·±åŒ–å›½é˜²å’Œå†›é˜Ÿæ”¹é©æ˜¯ä¸€åœºæ•´ä½“æ€§ã€é©å‘½æ€§å˜é©ï¼Œå¿…é¡»å§‹ç»ˆåœ¨å…šä¸­å¤®ã€ä¸­å¤®å†›å§”å’Œä¹ ä¸»å¸­çš„ç»Ÿä¸€é¢†å¯¼ä¸‹ï¼Œæ·±å…¥è´¯å½»ä¸­å¤®å†›å§”æ”¹é©å·¥ä½œä¼šè®®ç²¾ç¥ï¼ŒåšæŒæŠŠåŠ å¼ºæ•™è‚²ã€ç»Ÿä¸€æ€æƒ³è´¯ç©¿å§‹ç»ˆï¼ŒæŠŠå¼ºåŒ–è´£ä»»ã€è½ç»†è½å®è´¯ç©¿å§‹ç»ˆï¼ŒæŠŠä¾æ³•æ¨è¿›ã€ç¨³æ‰ç¨³æ‰“è´¯ç©¿å§‹ç»ˆï¼ŒæŠŠåº•çº¿æ€ç»´ã€ç®¡æ§é£é™©è´¯ç©¿å§‹ç»ˆï¼Œä»¥åšå¼ºæœ‰åŠ›çš„ç»„ç»‡é¢†å¯¼ä¿è¯å„é¡¹æ”¹é©ä»»åŠ¡åœ†æ»¡å®Œæˆã€‚\\n'},\n",
       " {'headline': 'ã€Šä¹ è¿‘å¹³å…³äºä¸¥æ˜å…šçš„çºªå¾‹å’Œè§„çŸ©è®ºè¿°æ‘˜ç¼–ã€‹å‡ºç‰ˆå‘è¡Œ',\n",
       "  'content': 'ç”±ä¸­å…±ä¸­å¤®çºªå¾‹æ£€æŸ¥å§”å‘˜ä¼šã€ä¸­å…±ä¸­å¤®æ–‡çŒ®ç ”ç©¶å®¤ç¼–è¾‘çš„ã€Šä¹ è¿‘å¹³å…³äºä¸¥æ˜å…šçš„çºªå¾‹å’Œè§„çŸ©è®ºè¿°æ‘˜ç¼–ã€‹ä¸€ä¹¦ï¼Œè¿‘æ—¥ç”±ä¸­å¤®æ–‡çŒ®å‡ºç‰ˆç¤¾ã€ä¸­å›½æ–¹æ­£å‡ºç‰ˆç¤¾å‡ºç‰ˆï¼Œåœ¨å…¨å›½å‘è¡Œã€‚\\nå…šçš„åå…«å¤§ä»¥æ¥ï¼Œä¸­å…±ä¸­å¤®æ€»ä¹¦è®°ã€å›½å®¶ä¸»å¸­ã€ä¸­å¤®å†›å§”ä¸»å¸­ä¹ è¿‘å¹³é«˜åº¦é‡è§†å…¨é¢ä»ä¸¥æ²»å…šï¼Œç«™åœ¨å…šå’Œå›½å®¶å…¨å±€çš„é«˜åº¦ï¼Œå›´ç»•ä¸¥æ˜å…šçš„çºªå¾‹å’Œè§„çŸ©ï¼Œå‘è¡¨äº†ä¸€ç³»åˆ—é‡è¦è®ºè¿°ï¼Œä¸ºåŠ å¼ºå…šçš„å»ºè®¾ï¼Œæ·±å…¥æ¨è¿›å…šé£å»‰æ”¿å»ºè®¾å’Œåè…è´¥æ–—äº‰æä¾›äº†æ€æƒ³æŒ‡å¯¼å’Œè¡ŒåŠ¨æŒ‡å—ã€‚è®¤çœŸå­¦ä¹ è´¯å½»è¿™äº›é‡è¦è®ºè¿°ï¼Œå¯¹äºå…¨å…šæ·±åˆ»è®¤è¯†åšæŒå…šçš„é¢†å¯¼ã€åŠ å¼ºå…šçš„å»ºè®¾çš„æç«¯é‡è¦æ€§ï¼Œå‡†ç¡®æŠŠæ¡çºªå¾‹å»ºè®¾çš„åŸºæœ¬è¦æ±‚ï¼Œè´¯å½»æ‰§è¡Œæ–°ä¿®è®¢çš„å»‰æ´è‡ªå¾‹å‡†åˆ™å’Œå…šçºªå¤„åˆ†æ¡ä¾‹ï¼Œåšå®šä¸ç§»æ¨è¿›å…¨é¢ä»ä¸¥æ²»å…šï¼Œå…·æœ‰ååˆ†é‡è¦çš„æ„ä¹‰ã€‚\\nã€Šè®ºè¿°æ‘˜ç¼–ã€‹å…±åˆ†7ä¸ªä¸“é¢˜ï¼šåŠ å¼ºçºªå¾‹å»ºè®¾æ˜¯å…¨é¢ä»ä¸¥æ²»å…šçš„æ²»æœ¬ä¹‹ç­–ï¼›ä¸¥æ˜å…šçš„çºªå¾‹ï¼Œé¦–è¦çš„å°±æ˜¯ä¸¥æ˜æ”¿æ²»çºªå¾‹ï¼›ä¸¥æ˜å…šçš„ç»„ç»‡çºªå¾‹ï¼Œå¢å¼ºç»„ç»‡çºªå¾‹æ€§ï¼›åˆ›æ–°å…šå†…æ³•è§„åˆ¶åº¦ï¼ŒæŠŠå„é¡¹çºªå¾‹å’Œè§„çŸ©ç«‹èµ·æ¥ï¼›ä½¿çºªå¾‹çœŸæ­£æˆä¸ºå¸¦ç”µçš„é«˜å‹çº¿;æŠ“ä½é¢†å¯¼å¹²éƒ¨è¿™ä¸ªâ€œå…³é”®å°‘æ•°â€ï¼›è½å®ç®¡å…šæ²»å…šè´£ä»»ï¼Œå¼ºåŒ–ç›‘ç£æ‰§çºªé—®è´£ã€‚ä¹¦ä¸­æ”¶å…¥200æ®µè®ºè¿°ï¼Œæ‘˜è‡ªä¹ è¿‘å¹³åŒå¿—2012å¹´11æœˆ16æ—¥è‡³2015å¹´10æœˆ29æ—¥æœŸé—´çš„è®²è¯ã€æ–‡ç« ç­‰40å¤šç¯‡é‡è¦æ–‡çŒ®ã€‚å…¶ä¸­è®¸å¤šè®ºè¿°æ˜¯ç¬¬ä¸€æ¬¡å…¬å¼€å‘è¡¨ã€‚\\næ—¥å‰ï¼Œä¸­å¤®çºªå§”æœºå…³ã€ä¸­å¤®å®£ä¼ éƒ¨è”åˆä¸‹å‘é€šçŸ¥ï¼Œè¦æ±‚å„çº§å…šç»„ç»‡è®¤çœŸç»„ç»‡å­¦ä¹ ä¹ è¿‘å¹³æ€»ä¹¦è®°å…³äºä¸¥æ˜å…šçš„çºªå¾‹å’Œè§„çŸ©çš„é‡è¦è®ºè¿°ï¼Œåˆ‡å®æ‹…è´Ÿèµ·å…¨é¢ä»ä¸¥æ²»å…šçš„ä¸»ä½“è´£ä»»ï¼ŒåšæŒé«˜æ ‡å‡†ï¼Œå®ˆä½åº•çº¿ï¼ŒçœŸæ­£æŠŠçºªå¾‹ç«‹èµ·æ¥ã€ä¸¥èµ·æ¥ï¼Œæ‰§è¡Œåˆ°ä½ï¼Œä¸ºåè°ƒæ¨è¿›â€œå››ä¸ªå…¨é¢â€æˆ˜ç•¥å¸ƒå±€æä¾›åšå¼ºçºªå¾‹ä¿è¯ã€‚\\nä»ä»Šå¤©èµ·ï¼Œã€Šä¸­å›½å…±äº§å…šå»‰æ´è‡ªå¾‹å‡†åˆ™ã€‹å’Œã€Šä¸­å›½å…±äº§å…šçºªå¾‹å¤„åˆ†æ¡ä¾‹ã€‹æ­£å¼æ–½è¡Œã€‚\\n'},\n",
       " {'headline': 'ä»¥å®é™…è¡ŒåŠ¨å‘å…šä¸­å¤®çœ‹é½ å‘é«˜æ ‡å‡†åŠªåŠ›',\n",
       "  'content': 'å¹¿å¤§å…šå‘˜å¹²éƒ¨æ­£åœ¨ç§¯æå­¦ä¹ ä¹ è¿‘å¹³æ€»ä¹¦è®°åœ¨ä¸­å¤®æ”¿æ²»å±€ä¸“é¢˜æ°‘ä¸»ç”Ÿæ´»ä¼šä¸Šçš„é‡è¦è®²è¯ã€‚å¤§å®¶çº·çº·è¡¨ç¤ºè¦æŠŠè·µè¡Œâ€œä¸‰ä¸¥ä¸‰å®â€ä½“ç°åœ¨è§£å†³é—®é¢˜çš„å®è·µå½“ä¸­ï¼Œä»¥å®é™…è¡ŒåŠ¨å‘å…šä¸­å¤®çœ‹é½ã€å‘é«˜æ ‡å‡†åŠªåŠ›ã€‚\\nä¸­å¤®æ”¿æ²»å±€ä¸“é¢˜æ°‘ä¸»ç”Ÿæ´»ä¼šä¸Šæå‡ºï¼Œåœ¨è·µè¡Œâ€˜ä¸‰ä¸¥ä¸‰å®â€™ä¸Šè¦å®šä½å‡†ã€æ ‡æ†é«˜ã€è¡Œä¹‹ç¬ƒï¼Œä»¥å®é™…è¡ŒåŠ¨ä¸è¾œè´Ÿäººæ°‘é‡æ‰˜ã€‚\\nè·µè¡Œâ€œä¸‰ä¸¥ä¸‰å®â€ï¼Œå°±è¦åšå®šç†æƒ³ä¿¡å¿µï¼Œæ°¸è‘†å…¨å¿ƒä¸ºæ°‘çš„å…¬ä»†æƒ…æ€€ï¼Œä¿æŒå¯¹å…šå¿ è¯šçš„æ”¿æ²»å“æ ¼ï¼Œåšæ”¿æ²»ä¸Šçš„æ˜ç™½äººã€‚\\n'}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ç™»éŒ²ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ç¢ºèª\n",
    "registered_samples = tfidf_matrix.shape[0]\n",
    "\n",
    "# æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹éš›ã«ã€ç™»éŒ²ã‚µãƒ³ãƒ—ãƒ«æ•°ä»¥ä¸‹ã®n_neighborsã‚’è¨­å®š\n",
    "def search_news_fixed(query, k=5):\n",
    "    # kã‚’ç™»éŒ²ã‚µãƒ³ãƒ—ãƒ«æ•°ä»¥ä¸‹ã«èª¿æ•´\n",
    "    k = min(k, registered_samples)\n",
    "    # è³ªå•ã‚’TF-IDFã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    # æœ€è¿‘å‚æ¤œç´¢\n",
    "    distances, indices = knn_index.kneighbors(query_vector, n_neighbors=k)\n",
    "    # æ¤œç´¢çµæœã‚’è¿”ã™\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        results.append({\n",
    "            \"headline\": data.iloc[idx][\"headline\"],\n",
    "            \"content\": data.iloc[idx][\"content\"]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# ä¿®æ­£ç‰ˆã§æ¤œç´¢ã®ä¾‹\n",
    "example_query = \"å›½é˜²ã¨è»éšŠã®æ”¹é©\"\n",
    "search_results_fixed = search_news_fixed(example_query)\n",
    "\n",
    "# ä¿®æ­£ç‰ˆã®æ¤œç´¢çµæœã‚’è¡¨ç¤º\n",
    "search_results_fixed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
